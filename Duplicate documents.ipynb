{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The purpose of this notebook is to use different methods to calculate the similarity between two documents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the similarity of the entire document text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import spacy\n",
    "import time\n",
    "\n",
    "startTime = time.time()\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "#The json is provided by the OCR process and is stored in Azure\n",
    "jsonPath1 = \"\" #Enter the path to the document json here.\n",
    "jsonPath2 = \"\" #Enter the path to the document json here. \n",
    "\n",
    "with open(jsonPath1, encoding='utf-8') as doc1Json:\n",
    "    doc1Data = json.load(doc1Json)\n",
    "\n",
    "with open(jsonPath2, encoding='utf-8') as doc2Json:\n",
    "    doc2Data = json.load(doc2Json)\n",
    "    \n",
    "doc1Text = nlp(doc1Data[\"Text\"].strip())\n",
    "doc2Text = nlp(doc2Data[\"Text\"].strip())\n",
    "docSimilarity = doc1Text.similarity(doc2Text)\n",
    "totalSimilarityTime = time.time() - startTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the luminance of every pixel, then match pixels between the two images. \n",
    "## This assumes a pixel is either black or white based on the luminance calculation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "startLuminanceTime = time.time()\n",
    "\n",
    "imgPath1 = \"\" #Add the path of the image you want to analyze here\n",
    "imgPath2 = \"\" #Add the path of the image you want to analyze here\n",
    "img = cv2.imread(imgPath1)\n",
    "img2 = cv2.imread(imgPath2)\n",
    "smallImg2 = cv2.resize(img2, (img.shape[1], img.shape[0]))\n",
    "smallImg = cv2.resize(img, None, fx=0.05, fy=0.05, interpolation = cv2.INTER_AREA)\n",
    "smallImg2 = cv2.resize(img2, None, fx=0.05, fy=0.05, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "def GetLuminancePerPixel(image):\n",
    "    testtime = time.time()\n",
    "    pixelLuminance = []\n",
    "    height, width = image.shape[0], image.shape[1]\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            R = image[y, x][2]\n",
    "            G = image[y, x][1]\n",
    "            B = image[y, x][0]\n",
    "            luminance = ((R / 255.0) * 0.3 + (G / 255.0) * 0.59 + (B / 255.0) * 0.11);\n",
    "            if(luminance < 0.75):\n",
    "                pixelLuminance.append(True)\n",
    "            else:\n",
    "                pixelLuminance.append(False)\n",
    "    return pixelLuminance\n",
    "\n",
    "imgLuminance = GetLuminancePerPixel(smallImg)\n",
    "img2Luminance = GetLuminancePerPixel(smallImg2)\n",
    "\n",
    "pixelsMatched = 0;\n",
    "for a, b in zip(imgLuminance, img2Luminance):\n",
    "    if(a == b):\n",
    "        pixelsMatched += 1\n",
    "totalLuminanceTime = time.time() - startLuminanceTime\n",
    "\n",
    "# To see the output images, use the code below\n",
    "# cv2.imshow(\"small\", smallImg) \n",
    "# cv2.imshow(\"small2\", smallImg2)\n",
    "# cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSIM (Structural similarity index) calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.measure import compare_ssim\n",
    "import argparse\n",
    "import imutils\n",
    "\n",
    "startSSIMTime = time.time()\n",
    "\n",
    "imageA = img\n",
    "imageB = img2\n",
    "\n",
    "height, width, channel = imageA.shape\n",
    "imageB = cv2.resize(imageB, (width, height))\n",
    "\n",
    "grayA = cv2.cvtColor(imageA, cv2.COLOR_BGR2GRAY)\n",
    "grayB = cv2.cvtColor(imageB, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "grayA = cv2.bitwise_not(grayA)\n",
    "grayB = cv2.bitwise_not(grayB)\n",
    "\n",
    "(score, diff) = compare_ssim(grayA, grayB, full=True)\n",
    "diff = (diff * 255).astype(\"uint8\")\n",
    "\n",
    "totalSSIMTime = time.time() - startSSIMTime\n",
    "\n",
    "# To see the output images, use the code below\n",
    "# thresh = cv2.threshold(diff, 0, 255,\n",
    "# cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "# cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "# cv2.CHAIN_APPROX_SIMPLE)\n",
    "# cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
    "# for c in cnts:\n",
    "#     (x, y, w, h) = cv2.boundingRect(c)\n",
    "#     cv2.rectangle(imageA, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "#     cv2.rectangle(imageB, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "\n",
    "# imageAResized = imutils.resize(imageA, height = 900)\n",
    "# imageBResized = imutils.resize(imageB, height = 900)\n",
    "# diff = imutils.resize(diff, height = 900)\n",
    "\n",
    "# cv2.imshow(\"Original\", imageAResized)\n",
    "# cv2.imshow(\"Modified\", imageBResized)\n",
    "# cv2.imshow(\"Diff\", diff)\n",
    "# cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the semantic similarity of each paragraph on two given pages and then get the average semantic similarity between the two pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "startParagraphTime = time.time()\n",
    "\n",
    "def getPageParagraphs(path):\n",
    "    with open(path, encoding='utf-8') as jsonFile:\n",
    "        data = json.load(jsonFile)\n",
    "\n",
    "    pageParagraphs = []\n",
    "    for i in range(len(data)):\n",
    "        pageParagraphs.append(data[i][\"Text\"])\n",
    "\n",
    "    return pageParagraphs\n",
    "\n",
    "page1JsonPath = \"\" #Json of the page to analyze\n",
    "page2JsonPath = \"\" #Json of the page to analyze\n",
    "p1Paragraphs = getPageParagraphs(page1JsonPath)\n",
    "p2Paragraphs = getPageParagraphs(page2JsonPath)\n",
    "\n",
    "def getSemanticSimilarityForParagraph(paragraph, paragraphList): \n",
    "    highestSemanticSimilarity = 0;\n",
    "    for i in range(len(paragraphList)):\n",
    "        text1 = nlp(paragraph.strip())\n",
    "        text2 = nlp(paragraphList[i].strip())\n",
    "        similarity = text1.similarity(text2)\n",
    "        if(similarity == 100):\n",
    "            return similarity\n",
    "        if(similarity > highestSemanticSimilarity):\n",
    "            highestSemanticSimilarity = similarity\n",
    "    return highestSemanticSimilarity\n",
    "\n",
    "similaritySum = 0\n",
    "\n",
    "for i in range(len(p1Paragraphs)):\n",
    "    similaritySum  += getSemanticSimilarityForParagraph(p1Paragraphs[i], p2Paragraphs)\n",
    "\n",
    "totalParagraphTime = time.time() - startParagraphTime\n",
    "totalTime = time.time() - startTime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This operation took: 10.00 s\n",
      "Semantic similarity for the entire doc text: 99.09 %. This took: 0.88 s\n",
      "Pixel match: 17039 out of 20111 px. 84.72 % match. This took: 0.43 s\n",
      "SSIM: 76.60 %. This took: 1.30 s\n",
      "Average semantic similarity across paragraphs: 85.24 %. This took: 7.00 s\n"
     ]
    }
   ],
   "source": [
    "print(\"This operation took:\", \"%.2f\" %totalTime,\"s\")\n",
    "print(\"Semantic similarity for the entire doc text:\", \"%.2f\" % (docSimilarity * 100), \"%. This took:\", \"%.2f\" % totalSimilarityTime, \"s\")\n",
    "print(\"Pixel match:\", pixelsMatched, \"out of\", len(imgLuminance), \"px.\", \"%.2f\" % (pixelsMatched / len(imgLuminance) * 100), \"% match. This took:\", \"%.2f\" % totalLuminanceTime, \"s\")\n",
    "print(\"SSIM:\", \"%.2f\" % (score * 100), \"%. This took:\", \"%.2f\" % totalSSIMTime, \"s\")\n",
    "print(\"Average semantic similarity across paragraphs:\", \"%.2f\" % (similaritySum / len(p1Paragraphs) * 100), \"%. This took:\", \"%.2f\" % totalParagraphTime, \"s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
